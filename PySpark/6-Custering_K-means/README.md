# 1. Clustering

Until now we have seen supervised Machine Learning where the target variable or label is known to us, and we try to predict the output based on the input features. 

Unsupervised Learning is different in a sense that there is no labeled data, and we don’t try to predict any output
as such; instead we try to find interesting patterns and come up with groups within the data. The similar values are grouped together.

We can apply clustering on any sort of data where we want to form groups
of similar observations and use it for better decision making. When we start clustering, each observation is different and doesn’t
belong to any group but is based on how similar are the attributes of each observation. We group them in such a way that each group contains the most similar records, and there is as much difference as possible between any two groups. The similarity between observation can be obtained by:

- Euclidean distance

- Manhattan Distance

- Mahalanobis Distance

- Minkowski Distances

- Chebyshev Distance

- Cosine Distance

