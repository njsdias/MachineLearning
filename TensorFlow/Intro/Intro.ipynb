{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-50a54b99565f>:21: make_csv_dataset (from tensorflow.contrib.data.python.ops.readers) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.make_csv_dataset(...)`.\n",
      "WARNING:tensorflow:From C:\\Users\\ctw00071\\AppData\\Local\\Continuum\\miniconda3\\envs\\test_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:532: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "OrderedDict([('spal_lenght', <tf.Tensor: id=59, shape=(32,), dtype=float32, numpy=\n",
      "array([5.6, 6.7, 6.9, 7.3, 6.1, 6.4, 5. , 5.4, 5.8, 6.3, 6.2, 5. , 5.4,\n",
      "       4.5, 5. , 4.6, 6.1, 5.4, 4.9, 5.8, 7.7, 5. , 4.4, 5.8, 6.4, 6.4,\n",
      "       6.1, 4.6, 5.4, 5.5, 6.9, 6.5], dtype=float32)>), ('sepal_width', <tf.Tensor: id=58, shape=(32,), dtype=float32, numpy=\n",
      "array([2.7, 3.1, 3.1, 2.9, 2.6, 3.2, 3.4, 3.4, 2.7, 3.3, 2.8, 3.6, 3.7,\n",
      "       2.3, 2.3, 3.2, 3. , 3.9, 3.1, 2.8, 3.8, 3.4, 2.9, 2.6, 2.8, 3.2,\n",
      "       2.8, 3.4, 3. , 2.6, 3.1, 3.2], dtype=float32)>), ('petal_length', <tf.Tensor: id=56, shape=(32,), dtype=float32, numpy=\n",
      "array([4.2, 5.6, 5.1, 6.3, 5.6, 4.5, 1.5, 1.5, 4.1, 4.7, 4.8, 1.4, 1.5,\n",
      "       1.3, 3.3, 1.4, 4.9, 1.3, 1.5, 5.1, 6.7, 1.6, 1.4, 4. , 5.6, 5.3,\n",
      "       4.7, 1.4, 4.5, 4.4, 4.9, 5.1], dtype=float32)>), ('petal_width', <tf.Tensor: id=57, shape=(32,), dtype=float32, numpy=\n",
      "array([1.3, 2.4, 2.3, 1.8, 1.4, 1.5, 0.2, 0.4, 1. , 1.6, 1.8, 0.2, 0.2,\n",
      "       0.3, 1. , 0.2, 1.8, 0.4, 0.1, 2.4, 2.2, 0.4, 0.2, 1.2, 2.1, 2.3,\n",
      "       1.2, 0.3, 1.5, 1.2, 1.5, 2. ], dtype=float32)>)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import os\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "train_dataset_url = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url), origin=train_dataset_url)\n",
    "\n",
    "column_names = ['spal_lenght', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "feature_names = column_names[:1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.contrib.data.make_csv_dataset(train_dataset_fp,\n",
    "                                                 batch_size, \n",
    "                                                 column_names=column_names,\n",
    "                                                 label_name=label_name, \n",
    "                                                 num_epochs=1)\n",
    "\n",
    "features,lables = next(iter(train_dataset))\n",
    "\n",
    "print(features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
